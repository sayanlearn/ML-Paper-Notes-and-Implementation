{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Named_entity_recognition_v1.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11Y1pi_hVOtXooMAo0T5gEDY9buwBD3VH",
      "authorship_tag": "ABX9TyMEipCzCWT6K66vO/zEIxdr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanlearn/ML-Paper-Notes-and-Implementation/blob/master/Named_entity_recognition_v1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rABEhQmBCTJX",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuqNsnEqCWEI",
        "colab_type": "text"
      },
      "source": [
        "## Uploading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpVgVbAsHd-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "ds = pd.read_csv('/content/drive/My Drive/Named Entity Recognition/ner_dataset.csv', engine='python') # To remove the unicode error (stackoverflow), engine = 'python' was added"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idT112xRS5-_",
        "colab_type": "text"
      },
      "source": [
        "## Preparation of training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqltlBpRSaGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = ds[\"Tag\"].tolist()\n",
        "# This list consists of all the tags corresponding to all the words in the dataset\n",
        "tag = []\n",
        "for t in tags:\n",
        "  if t in tag:\n",
        "    continue\n",
        "  else:\n",
        "    tag.append(t)\n",
        "# tag consists of all the possible categories "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfYnj_kpTya3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "op = []\n",
        "for i in range(len(tags)):\n",
        "  for j in range(len(tag)):\n",
        "    if tags[i] == tag[j]:\n",
        "      op.append(j)\n",
        "# We have now converted the output to label form"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6acduqzV4fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = ds[\"Word\"].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koNFqbI7ZO-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = []\n",
        "for m in w:\n",
        "  if m in vocab:\n",
        "    continue\n",
        "  else:\n",
        "    vocab.append(m)\n",
        "# We will create a vocabulary consisting of all possible words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCuOpUYhZPnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic = {}\n",
        "i = 0\n",
        "for m in range(len(w)):\n",
        "  if w[m] == '.':\n",
        "    j = m+1\n",
        "    ix = tuple(w[i:j]) # Tuples can be used as keys in dictionaries and not lists\n",
        "    ox = op[i:j]\n",
        "    dic[ix] = ox\n",
        "    i = j\n",
        "# We have now segregated the sentences with the help of full stops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrzwJMa9ZvUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = list(dic.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdzKfQRCbrQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxx = 0\n",
        "for i in l:\n",
        "  j = len(i)\n",
        "  if j > maxx:\n",
        "    maxx = j \n",
        "# We will find the max length of any sentence so that we can add appropriate padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ToJcI4fcz0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dicn = {}\n",
        "for ix, ox in dic.items():\n",
        "  ixn = list(ix)\n",
        "  for i in range(maxx + 2 - len(ixn)):\n",
        "    ixn.append('a')\n",
        "    ox.append(0) \n",
        "  ixnn = tuple(ixn)\n",
        "  dicn[ixnn] = ox\n",
        "# We have done with padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5u2FQ1Bir-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def w2v(w):\n",
        "  a = []\n",
        "  for j in range(len(vocab)):\n",
        "    a.append(0)\n",
        "  for i in range(len(vocab)):\n",
        "    if w == vocab[i]:\n",
        "      a[i] = 1\n",
        "  return a\n",
        "# We have created a function to convert a word as a one hot encoding form"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5xTTv46wD86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def o2o(n):\n",
        "  a = []\n",
        "  for j in range(len(tag)):\n",
        "    a.append(0)\n",
        "  a[n] = 1\n",
        "  return a\n",
        "# To create one hot enoding for the ooutput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOH6pdGvkRIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = []\n",
        "oup = []\n",
        "for ix, ox in dicn.items():\n",
        "  ix = list(ix)\n",
        "  inp.append(ix)\n",
        "  oup.append(ox)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jihq5gCrnLWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inpn = []\n",
        "m = 0\n",
        "for i in inp:\n",
        "  x = []\n",
        "  for j in i:\n",
        "    x.append(w2v(j))\n",
        "  a = x.copy()\n",
        "  inpn.append(a)\n",
        "  m = m + 1\n",
        "  if m == 100:\n",
        "    break\n",
        "inpn = np.array(inpn)\n",
        "r = inpn.shape\n",
        "inpn = inpn.reshape((r[0], r[2], r[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rej-QDaRrSEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oupn = []\n",
        "m = 0\n",
        "for i in oup:\n",
        "  x = []\n",
        "  for j in i:\n",
        "    x.append(o2o(j))\n",
        "  a = x.copy()\n",
        "  oupn.append(a)\n",
        "  m = m + 1\n",
        "  if m == 100:\n",
        "    break\n",
        "oupn = np.array(oupn)\n",
        "r = oupn.shape\n",
        "oupn = oupn.reshape((r[0], r[2], r[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I72bOirR4vJE",
        "colab_type": "text"
      },
      "source": [
        "## Training DL Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utQyJqJe0qrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvMxbvYm4_2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformx = transforms.Compose([ \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class trainset(data.Dataset):\n",
        "\n",
        "  def __init__(self, transform = None):\n",
        "    self.ip = inpn\n",
        "    self.label = oupn\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return m\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    ix = self.transform(self.ip[index])\n",
        "    ox = self.transform(self.label[index])\n",
        "    return ix, ox\n",
        "\n",
        "traindataset = trainset(transformx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTzmMWs460KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = data.DataLoader(traindataset, batch_size = 2, shuffle = True, num_workers = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttCxnWxE7Aiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, data in enumerate(train_loader):\n",
        "  continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilnOn1P68J_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "930f2ea0-f32e-49b7-aca0-8f43fdf48e72"
      },
      "source": [
        "data[1].size()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 17, 106])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGYRCaAZ8XIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "    super().__init__()\n",
        "    # Hidden Dimensions\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    # Number of hidden layers\n",
        "    self.layer_dim = layer_dim\n",
        "\n",
        "    # Building your RNN\n",
        "    # batch_first=True causes input/output tensors to be of shape\n",
        "    # (batch_dim, seq_dim, input_dim)\n",
        "    # batch_dim = number of samples per batch\n",
        "    self.RN = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out, hn = self.RN(x, None)\n",
        "    # out.shape() = (batch, seq_dim, hidden_size*input_dim)\n",
        "    # hn is the hidden state of the last time step\n",
        "    out = self.fc(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz5TEfjUF6m7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = 35165\n",
        "hidden_dim = 30\n",
        "layer_dim = 1\n",
        "output_dim = 17"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcWBanSdG6we",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNN(input_dim, hidden_dim, layer_dim, output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0NWnPPfHGDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss();\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01, betas = (0.9, 0.999), eps = 1e-08, weight_decay=0, amsgrad=False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpcYlqS0HUNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "cb036948-2a54-416e-8741-0c27aefa1a14"
      },
      "source": [
        "for j in range(10):\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, label = data\n",
        "    inputs = inputs.reshape(2, 106, input_dim)\n",
        "    label = label.reshape(2, 106, output_dim)\n",
        "    inputs = inputs.float()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(inputs)\n",
        "    loss = criterion(output, label.argmax(dim=2))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(loss.item())"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-3ff5be4afec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 932\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 2125\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   2126\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected target size (2, 17), got torch.Size([2, 106])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pao0_1QZIbQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73f7dea6-77ba-44aa-bbe3-605bbc660191"
      },
      "source": [
        "label.argmax(dim = 2).size()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 106])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9_PRyocLuOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}